{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A simple DL model using Keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNUjQsD0Yruw"
      },
      "source": [
        "\n",
        "A Simple Deep Learning model using keras.\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Keras Model Life-Cycle\n",
        "Below is an overview of the 5 steps in the neural network model life-cycle in Keras:**\n",
        "1. Analyze the dataset\n",
        "2. Prepare the data Set\n",
        "3. Define Network.\n",
        "4. Compile Network.\n",
        "5. Fit Network.\n",
        "6. Evaluate Network.\n",
        "7. Make Predictions.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOAk10HtZrT7",
        "outputId": "bcf1d0dc-9df3-46b6-820a-eccf4abdd44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta1 #Tensorflow beta version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__) # Check the version"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta1) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.2.0)\n",
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsZSs0Wob2px"
      },
      "source": [
        "Preparing the data : \n",
        "\n",
        "First, we import the data. It is made up of 60,000 images for the training set and 10,000 images for the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmspZZj7bROL"
      },
      "source": [
        "import tensorflow as tf # import tensorflow as tf for faster typing \n",
        "import numpy as np      # import numerical python as np\n",
        " \n",
        "num_classes = 10\n",
        "img_rows, img_cols = 28, 28\n",
        "num_channels = 1\n",
        "input_shape = (img_rows, img_cols, num_channels)\n",
        "(x_train, y_train),(x_test, y_test) =  tf.keras.datasets.mnist.load_data()     #load the datasets\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 #DataNormalization"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q67faAKIcHET"
      },
      "source": [
        "Define Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPDEUXUecPbW"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS3xxh4udFk7"
      },
      "source": [
        "Compile Network\n",
        "\n",
        "Calling .compile() on the model we just created is a mandatory step. A few arguments must be specified:\n",
        "\n",
        "optimizer: This is the component that will perform the gradient descent.\n",
        "\n",
        "loss: This is the metric we will optimize. In our case, we choose \n",
        "cross-entropy, just like in the previous chapter.\n",
        "\n",
        "metrics: These are additional metric functions evaluated during training to provide further visibility of the modelâ€™s performance (unlike loss, they are not used in the optimization process)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xib96tpnc9Dl"
      },
      "source": [
        "model.compile(optimizer='sgd',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_OyMZK8en1b"
      },
      "source": [
        "Fit Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGvhIIJJdPB7",
        "outputId": "3390527d-08a8-4c1c-f932-0bb84576a3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5, verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2181 - accuracy: 0.9384 - val_loss: 0.2066 - val_accuracy: 0.9398\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2029 - accuracy: 0.9424 - val_loss: 0.1924 - val_accuracy: 0.9432\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1896 - accuracy: 0.9463 - val_loss: 0.1828 - val_accuracy: 0.9471\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1779 - accuracy: 0.9496 - val_loss: 0.1725 - val_accuracy: 0.9490\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1678 - accuracy: 0.9527 - val_loss: 0.1671 - val_accuracy: 0.9513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f414f99d2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzq-rJBCe6KC"
      },
      "source": [
        "Evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAIvOaXvexVJ",
        "outputId": "0b85260d-13d8-4482-8651-3ccedd298f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 35us/sample - loss: 0.1671 - accuracy: 0.9513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16714542947560548, 0.9513]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRyyN324fLrQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}